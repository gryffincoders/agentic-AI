# -*- coding: utf-8 -*-
"""Agentic AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XJh2skl8TibNJhr93TO0ZQMQN7GLq0de
"""

!pip install transformers sentencepiece accelerate pypdf2 --quiet

from transformers import pipeline
import PyPDF2
import re

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

def extract_text_from_pdf(file_path):
    text = ""
    with open(file_path, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        for page in reader.pages:
            text += page.extract_text() + "\n"
    return text

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)  # Remove excessive spaces
    text = re.sub(r'\n', ' ', text)  # Remove newlines
    return text.strip()

def analyze_financial_report(file_path):
    # Extract & clean text
    raw_text = extract_text_from_pdf(file_path)
    clean_data = clean_text(raw_text)

    # Hugging Face summarization
    summary = summarizer(clean_data, max_length=300, min_length=100, do_sample=False)[0]['summary_text']

    # Simple keyword-based extraction
    insights = {
        "Revenue": re.findall(r"Revenue[\w\s:]*\$?[\d,.]+", clean_data, re.IGNORECASE),
        "Profit": re.findall(r"Profit[\w\s:]*\$?[\d,.]+", clean_data, re.IGNORECASE),
        "Loss": re.findall(r"Loss[\w\s:]*\$?[\d,.]+", clean_data, re.IGNORECASE),
        "Expenses": re.findall(r"Expenses[\w\s:]*\$?[\d,.]+", clean_data, re.IGNORECASE)
    }

    return {
        "summary": summary,
        "insights": insights
    }

from google.colab import files
uploaded = files.upload()

file_path = list(uploaded.keys())[0]

results = analyze_financial_report(file_path)

print("\n Financial Report Summary:\n")
print(results["summary"])

print("\n Key Insights:")
for key, value in results["insights"].items():
    print(f"{key}: {value if value else 'Not Found'}")